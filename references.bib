@Book{american_psychological_association_publication_2010,
  location = {{Washington, DC}},
  edition = {6th edition},
  title = {Publication {{Manual}} of the {{American Psychological Association}}},
  abstract = {The {"}Publication Manual{"} is the style manual of choice for writers, editors, students, and educators. Although it is specifically designed to help writers in the behavioral sciences and social sciences, anyone who writes non-fiction prose can benefit from its guidance. The newly-revised Sixth Edition has not only been rewritten. It has also been thoroughly rethought and reorganized, making it the most user-friendly {"}Publication Manual{"} the APA has ever produced. You will be able to find answers to your questions faster than ever before. When you need advice on how to present information, including text, data, and graphics, for publication in any type of format--such as college and university papers, professional journals, presentations for colleagues, and online publication--you will find the advice you're looking for in the {"}Publication Manual.{"}},
  pagetotal = {272},
  timestamp = {2015-05-28T15:11:27Z},
  langid = {english},
  publisher = {{American Psychological Association}},
  author = {{American Psychological Association}},
  date = {2010},
}
@Article{patil_statistical_2016,
  title = {A Statistical Definition for Reproducibility and Replicability},
  rights = {© 2016, Published by Cold Spring Harbor Laboratory Press. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  url = {http://biorxiv.org/content/early/2016/07/29/066803},
  doi = {10.1101/066803},
  abstract = {Everyone agrees that reproducibility and replicability are fundamental characteristics of scientific studies. These topics are attracting increasing attention, scrutiny, and debate both in the popular press and the scientific literature. But there are no formal statistical definitions for these concepts, which leads to confusion since the same words are used for different concepts by different people in different fields. We provide formal and informal definitions of scientific studies, reproducibility, and replicability that can be used to clarify discussions around these concepts in the scientific and popular press.},
  timestamp = {2016-09-25T18:54:40Z},
  langid = {english},
  journaltitle = {bioRxiv},
  author = {Prasad Patil and Roger D. Peng and Jeffrey Leek},
  urldate = {2016-09-25},
  date = {2016-07-29},
  pages = {066803},
  file = {Full Text PDF:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/KE7PHNI8/Patil et al. - 2016 - A statistical definition for reproducibility and r.pdf:application/pdf},
}
@Article{asendorpf_recommendations_2013,
  title = {Recommendations for {{Increasing Replicability}} in {{Psychology}}},
  volume = {27},
  issn = {1099-0984},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/per.1919/abstract},
  doi = {10.1002/per.1919},
  abstract = {Replicability of findings is at the heart of any empirical science. The aim of this article is to move the current replicability debate in psychology towards concrete recommendations for improvement. We focus on research practices but also offer guidelines for reviewers, editors, journal management, teachers, granting institutions, and university promotion committees, highlighting some of the emerging and existing practical solutions that can facilitate implementation of these recommendations. The challenges for improving replicability in psychological science are systemic. Improvement can occur only if changes are made at many levels of practice, evaluation, and reward. Copyright © 2013 John Wiley \& Sons, Ltd.},
  timestamp = {2016-09-25T19:40:32Z},
  langid = {english},
  number = {2},
  journaltitle = {European Journal of Personality},
  shortjournal = {Eur. J. Pers.},
  author = {Jens B. Asendorpf and Mark Conner and Filip {De Fruyt} and Jan {De Houwer} and Jaap J. A. Denissen and Klaus Fiedler and Susann Fiedler and David C. Funder and Reinhold Kliegl and Brian A. Nosek and Marco Perugini and Brent W. Roberts and Manfred Schmitt and Marcel A. G. {van Aken} and Hannelore Weber and Jelte M. Wicherts},
  urldate = {2016-09-25},
  date = {2013-03-01},
  pages = {108--119},
  keywords = {confirmation bias,generalizability,publication bias,replicability,research transparency},
  options = {useprefix=true},
  file = {Full Text PDF:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/WP2KB228/Asendorpf et al. - 2013 - Recommendations for Increasing Replicability in Ps.pdf:application/pdf},
}

@Report{cacioppo_social_2015,
  location = {{Arlington, VA}},
  title = {Social, {{Behavioral}}, and {{Economic Sciences Perspectives}} on {{Robust}} and {{Reliable Science}}},
  url = {http://web.stanford.edu/group/bps/cgi-bin/wordpress/wp-content/uploads/2015/09/NSF-Robust-Research-Workshop-Report.pdf},
  timestamp = {2016-09-25T19:52:32Z},
  institution = {{National Science Foundation}},
  type = {Report of the {{Subcommittee}} on {{Replicability}} in {{Science}}},
  author = {John T. Cacioppo and Robert M. Kaplan and Jon A. Krosnick and James L. Olds and Heather Dean},
  urldate = {2016-09-25},
  date = {2015},
  file = {SBE_Robust_and_Reliable_Research_Report.pdf:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/THRZE8PX/SBE_Robust_and_Reliable_Research_Report.pdf:application/pdf},
}
@Book{gandrud_reproducible_2013,
  location = {{Boca Raton}},
  edition = {Auflage: New.},
  title = {Reproducible Research with R and Rstudio},
  isbn = {978-1-4665-7284-3},
  abstract = {Bringing together computational research tools in one accessible source, Reproducible Research with R and RStudio guides you in creating dynamic and highly reproducible research. Suitable for researchers in any quantitative empirical discipline, it presents practical tools for data collection, data analysis, and the presentation of results. With straightforward examples, the book takes you through a reproducible research workflow, showing you how to use: * R for dynamic data gathering and automated results presentation * knitr for combining statistical analysis and results into one document * LaTeX for creating PDF articles and slide shows, and Markdown and HTML for presenting results on the web * Cloud storage and versioning services that can store data, code, and presentation files; save previous versions of the files; and make the information widely available * Unix-like shell programs for compiling large projects and converting documents from one markup language to another * RStudio to tightly integrate reproducible research tools in one place Whether you're an advanced user or just getting started with tools such as R and LaTeX, this book saves you time searching for information and helps you successfully carry out computational research. It provides a practical reproducible research workflow that you can use to gather and analyze data as well as dynamically present results in print and on the web. Supplementary files used for the examples and a reproducible research project are available on the author's website.},
  pagetotal = {294},
  timestamp = {2015-03-10T00:27:26Z},
  langid = {Englisch},
  publisher = {{Crc Pr Inc}},
  author = {Christopher Gandrud},
  date = {2013-08-21},
  file = {reproducible-research-with-r-and-studio-2nd-edition.pdf:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/SPV8KZZS/reproducible-research-with-r-and-studio-2nd-edition.pdf:application/pdf},
}
@Book{stodden_implementing_2014,
  location = {{Boca Raton}},
  title = {Implementing {{Reproducible Research}}},
  isbn = {978-1-4665-6159-5},
  url = {https://osf.io/s9tya/},
  abstract = {In computational science, reproducibility requires that researchers make code and data available to others so that the data can be analyzed in a similar manner as in the original publication. Code must be available to be distributed, data must be accessible in a readable format, and a platform must be available for widely distributing the data and code. In addition, both data and code need to be licensed permissively enough so that others can reproduce the work without a substantial legal burden. Implementing Reproducible Research covers many of the elements necessary for conducting and distributing reproducible research. It explains how to accurately reproduce a scientific result.   Divided into three parts, the book discusses the tools, practices, and dissemination platforms for ensuring reproducibility in computational science. It describes:   Computational tools, such as Sweave, knitr, VisTrails, Sumatra, CDE, and the Declaratron system Open source practices, good programming practices, trends in open science, and the role of cloud computing in reproducible research Software and methodological platforms, including open source software packages, RunMyCode platform, and open access journals  Each part presents contributions from leaders who have developed software and other products that have advanced the field. Supplementary material is available at www.ImplementingRR.org.},
  pagetotal = {448},
  timestamp = {2016-09-25T20:18:29Z},
  langid = {english},
  publisher = {{Chapman and Hall/CRC}},
  author = {Victoria Stodden and Friedrich Leisch and Roger D. Peng},
  date = {2014-04-14},
}
@Article{pfister_schorsch:_2016,
  title = {{{schoRsch}}: {{An R}} Package for Analyzing and Reporting Factorial Experiments},
  volume = {12},
  issn = {2292-1354},
  url = {http://www.tqmp.org/RegularArticles/vol12-2/p147},
  doi = {10.20982/tqmp.12.2.p147},
  shorttitle = {{{schoRsch}}},
  timestamp = {2016-09-26T07:00:03Z},
  number = {2},
  journaltitle = {The Quantitative Methods for Psychology},
  author = {Roland Pfister and Markus Janczyk},
  urldate = {2016-09-26},
  date = {2016-09-01},
  pages = {147--151},
  file = {p147.pdf:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/VN3TJBSD/p147.pdf:application/pdf},
}
